---
title: "Hyp testing, t-tests"
author: "HT"
date: "03/11/2022"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

Imagine that you are collecting data on cortisone levels in the blood of birds. Assume that the population of interest has an exponential distribution of blood cortisone levels with a mean of 3, and a population size of 4000 birds.

Create a histogram of the distribution of cortisone levels in the population.

```{r}
pop <- rexp(4000, rate = 1/3)
hist(pop, freq = FALSE)
```

Write a script that records a sampling distribution of 1000 samples of size 30.

```{r}
Sampling.dist <- c()  #creating an empty vector
n <- 30               #sample size
iterations <- 1000    #number of loop iterations

for (i in 1:iterations){
  Sampling.dist[i] = mean(sample(pop, n))
}

mean(Sampling.dist)
sd(Sampling.dist)

hist(Sampling.dist)
```

Now we are going to evaluate whether any particular sample is less than that of urban birds. Researchers interested in urban birds have established that urban populations have a mean cortisone level of 6.

Write out the null and alternate hypotheses for this question.
#########################################################################
H(0) -> mean(sample) >= mean(urban population)
H(A) -> mean(sample) <  mean(urban population)
#########################################################################

Is this null-alternate pair directional?
#########################################################################
Yes! - Remember, hyps are directional if you ask anything more than if your samples (or populations) are different. Here we ask if our sample mean is *less* than the population measure - hence directional.
#########################################################################

In order to evaluate for a difference, plot the null distribution based on the null hypothesis of 6 (ug/ml), based on both the real sampling distribution (as a histogram), and the estimated sampling distribution (as a pdf) from a single sample of size 30.  
#########################################################################
When we do a single sample T or Z test (where a sample is being compared to a population or an existing measure), we create a null distribution using a sneaky trick (much like most of statistics). 

What is this trick? You estimate a sampling distribution using your sample, and simply switch out the mean of this distribution and use that of the null hypothesis instead. In this case, our null hypothesis is based on the population mean given to us, i.e. 6. So we use our sampling distribution and simply change the mean to 6, to give us the null dist.
#########################################################################
```{r}
null_hyp <- 6
#NULL FROM MANUALLY COLLECTED SAMPLING DIST
null_dist <- c()
observed_mean <- mean(Sampling.dist)
null_obs_diff <- null_hyp - observed_mean
null_dist = Sampling.dist+null_obs_diff
null_dist_hist <- hist(null_dist, breaks = 16, xlim = c(0,12), xlab = "Cort levels", freq = F)

#ESTIMATED NULL
#parameters of the null distribution
samp <- sample(pop, n)
SE <- sd(samp)/sqrt(n)

xx <- seq(0,12,length=300)
null_dist_yy <- dnorm(xx, null_hyp, SE)
null_dist_pdf <- plot(xx, null_dist_yy, xlim = c(0,12), type = "l", xlab = "Cort levels", ylab = "Probability Density")
```

Using your single sample, evaluate the pair of hypothesis previously set out.

#########################################################################
Here our job is simply too check where the sample mean falls on the null distribution's range and to map out the area under the curve associated with it.
#########################################################################
```{r}
#Looking at our sample on the null distributions (manually sampled and estimated)

null_dist_hist <- hist(null_dist, breaks = 16, xlim = c(0,12), xlab = "Cort levels", freq = F); lines(xx, null_dist_yy); abline (v=3)

#Using the pnorm function to calculate probability
p <- pnorm(mean(samp), null_hyp, SE)
```

Repeat the exercise of calculating this probability, but this time using a sampling distribution with samples of size 5.

```{r}
n_smol <- 5
samp_smol <- sample(pop, n_smol)
SE_smol <- sd(samp_smol)/sqrt(n_smol)

xt <- seq(-6,6,length=300)
null_dist_yt <- dt(xt, n_smol-1)
null_dist_pdf <- plot(xt, null_dist_yt, type = "l", xlab = "Cort levels", ylab = "Probability Density")

t <- (mean(samp_smol)-null_hyp)/SE_smol
pt(t, n_smol-1)
```

A common misconception is that confidence intervals can be used to conduct hypothesis tests. The argument is that if the 95% confidence intervals fail to overlap that this implies statistical significance at the ⍺=5% level. There are of course philosophical reasons why this shouldn’t be done given that confidence intervals are based on the sampling distribution of your data whereas hypothesis tests are based on a null distribution. But even more importantly, this doesn't actually work, mathematically. We will explore this using the dataset 'cedars.csv'.

You are interested in the growth rate of cedar trees at two sites along the Niagara escarpment. The first site is near the cliff of the escarpment and the second site is alongside a clearing in the forest setback from the escarpment. 

We ask if growth rates are different between the sites. Is such a test a paired sample or 2 sample test?

Write out the null and alternate hypotheses for this question.

Is this null-alternate pair directional?
#########################################################################
H(0) -> Mean(esc)-Mean(frs) = 0; 

H(A) -> Mean(esc)-Mean(frs) =/= 0; 

Nope, not directional
#########################################################################

a> Conduct a test on this hypothesis.
b> Calculate the CI intervals for growth at both locations.

What can we interpret from these two results?
```{r}
cedars <- read.csv(file="/Users/ht/Stats/practice_data/cedars.csv")
cedars$Location <- as.factor(cedars$Location)

#t = [(m1-m2) - (µ1-µ2)] / √ (s1^2/n1 + s2^2/n2)
#However, the null hyp is that µ1-µ2 = 0
#df = n1 + n2 – 2

Forest <- cedars[cedars$Location=="Forest",]
Escarpment <- cedars[cedars$Location=="Escarpment",]

m1 <- mean(Escarpment$Growth)
m2 <- mean(Forest$Growth)

s1 <- sd(Escarpment$Growth)
s2 <- sd(Forest$Growth)

n1 <- length(Escarpment$Growth)
n2 <- length(Forest$Growth)

t <-(m1-m2)/sqrt(s1^2/n1 + s2^2/n2)

p <- 2*(pt(t,n1+n2-2))

CI <- function(x,p){
  t <- qt(p, (length(x$Growth)-1))
  Mean <- mean(x$Growth)
  SE <- sd(x$Growth)/sqrt(length(x$Growth))
  return(c(Mean+(t*SE), Mean-(t*SE)))
}

CI_95 <- cbind(c("Escarpment", "Forest"), rbind(CI(Escarpment, 0.025), CI(Forest, 0.025))); CI_95
```


T-tests inbuilt package:
```{r}
#2 sample basic test
t.test(y~x, data=data, var.equal=TRUE)

#Welch
t.test(y~x, data=data, var.equal=FALSE)

#paired t
t.test(x_before_treatment,x_after_treatment, data=data, paired=TRUE)
```